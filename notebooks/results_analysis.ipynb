{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30b6139",
   "metadata": {},
   "source": [
    "# Results & Diagnostics: Predictive, Interventional, and Robustness\n",
    "\n",
    "**Goal.** Evaluate models on **predictive fit**, **interventional fidelity**, and **robustness under interventions**, mirroring the thesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))  \n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "CONFIGS_DIR = PROJECT_ROOT / \"configs\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\" / \"finance\"\n",
    "BEST_DIR = CONFIGS_DIR / \"best_config.yaml\"\n",
    "\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os, yaml, json, math, torch, numpy as np, pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models import GNN_NCM\n",
    "from src.dataloader import CausalFactorDataset\n",
    "from src.trainer import CausalTwoPartTrainer  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb35b2",
   "metadata": {},
   "source": [
    "## 1. Load Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22feb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = Path(BEST_DIR)\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if (cfg.get(\"device\",\"cuda\") == \"cuda\" and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CausalFactorDataset(\n",
    "    root_dir=DATA_DIR,\n",
    "    drop_self_for_target=True,\n",
    ")\n",
    "split = int(0.8 * len(ds))\n",
    "train_loader = DataLoader(Subset(ds, range(split)), batch_size=cfg[\"data\"][\"batch_size\"], shuffle=True)\n",
    "val_loader   = DataLoader(Subset(ds, range(split, len(ds))), batch_size=cfg[\"data\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "\n",
    "# dims\n",
    "g0 = next(iter(train_loader))\n",
    "num_features = g0.num_node_features\n",
    "num_edges    = g0.edge_index.size(1)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"num_features={num_features} | num_edges={num_edges} | nodes={g0.num_nodes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093b1ae",
   "metadata": {},
   "source": [
    "## 2. Initializing Models and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19145c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_per_edge = GNN_NCM(\n",
    "    num_features=num_features,\n",
    "    num_edges=num_edges,\n",
    "    gnn_mode=cfg[\"model\"][\"gnn_mode\"],\n",
    "    hidden_dim=cfg[\"model\"][\"hidden_dim\"],\n",
    "    out_dim=cfg[\"model\"][\"out_dim\"],\n",
    "    noise_dim=cfg[\"model\"][\"noise_dim\"],\n",
    ").to(device)\n",
    "\n",
    "\n",
    "model_shared = GNN_NCM(\n",
    "    num_features=num_features,\n",
    "    num_edges=num_edges,\n",
    "    gnn_mode=\"shared\",\n",
    "    hidden_dim=cfg[\"model\"][\"hidden_dim\"],\n",
    "    out_dim=cfg[\"model\"][\"out_dim\"],\n",
    "    noise_dim=cfg[\"model\"][\"noise_dim\"],\n",
    "   \n",
    ").to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcfg = cfg[\"training\"]\n",
    "trainer = CausalTwoPartTrainer(\n",
    "    epochs_obs=tcfg[\"epochs_obs\"], epochs_do=tcfg[\"epochs_do\"],\n",
    "    lr=tcfg[\"lr\"], w_obs=tcfg[\"w_obs\"], w_do=tcfg[\"w_do\"],\n",
    "    weight_decay=tcfg[\"weight_decay\"], clip=tcfg[\"clip\"],\n",
    "    neutral=tcfg[\"neutral\"], delta=tcfg[\"delta\"]\n",
    ")\n",
    "\n",
    "trainer.train(model_per_edge, train_loader, val_loader=val_loader)\n",
    "val_mse_per_edge = trainer.evaluate_obs_mse(model_per_edge, val_loader)\n",
    "\n",
    "\n",
    "trainer.train(model_shared, train_loader, val_loader=val_loader)    \n",
    "val_mse_shared = trainer.evaluate_obs_mse(model_shared, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715420fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import BaselineGCN\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "baseline_model = BaselineGCN(num_features=num_features, hidden_dim=cfg[\"model\"][\"hidden_dim\"], out_dim=cfg[\"model\"][\"out_dim\"])\n",
    "optimizer_baseline = optim.Adam(baseline_model.parameters())\n",
    "loss_fn_baseline = nn.MSELoss()\n",
    "\n",
    "\n",
    "for ep in range(200):\n",
    "    for g in train_loader:\n",
    "        baseline_model.train()\n",
    "        optimizer_baseline.zero_grad()\n",
    "        pred = baseline_model(g.x, g.edge_index)\n",
    "        loss = loss_fn_baseline(pred, g.y)\n",
    "        loss.backward(); optimizer_baseline.step()\n",
    "    if (ep+1) % 40 == 0:\n",
    "        print(f\"[Baseline] ep {ep+1:03d} loss={loss.item():.4f}\")\n",
    "\n",
    "# quick baseline val\n",
    "baseline_model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0.0; n = 0\n",
    "    for g in val_loader:\n",
    "\n",
    "        VOL_IDX = ds.node_map[\"VOL\"]\n",
    "        total += float(( (baseline_model(g.x, g.edge_index).squeeze(-1)[VOL_IDX] - g.y.squeeze(-1)[VOL_IDX]) ** 2 ).item())\n",
    "        n += 1\n",
    "val_loss_bl = total / max(n,1)\n",
    "print(f\"[baseline] val_mse={val_loss_bl:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ecd73a",
   "metadata": {},
   "source": [
    "## 3. Predictive Fit\n",
    "\n",
    "- Metric: **MSE / RMSE** on `VOL` (validation split).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e390cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fit = {\n",
    "    \"per_edge\": {\"mse\": float(val_mse_per_edge), \"rmse\": float(np.sqrt(val_mse_per_edge))},\n",
    "    \"shared\":   {\"mse\": float(val_mse_shared),   \"rmse\": float(np.sqrt(val_mse_shared))},\n",
    "    \"gcn\":      {\"mse\": float(val_loss_bl),      \"rmse\": float(np.sqrt(val_loss_bl))},\n",
    "}\n",
    "print(pred_fit)\n",
    "\n",
    "with open(os.path.join(OUTPUTS_DIR, \"predictive_fit_vol.json\"), \"w\") as f:\n",
    "    json.dump(pred_fit, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166424a6",
   "metadata": {},
   "source": [
    "## 4. Robustness Stress Tests (Finance Panel)\n",
    "\n",
    "Two stress tests:\n",
    "1) `do(BAS = BAS + delta)`\n",
    "2) `do(Mom = Mom + delta)`\n",
    "\n",
    "Compute degradation ratio:\n",
    "\n",
    "- Plot bar chart of Deg per model; also plot absolute change in MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress degradation\n",
    "import numpy as np, json, os\n",
    "\n",
    "@torch.no_grad()\n",
    "def stress_degradation(model, loader, ops):\n",
    "    # factual MSE \n",
    "    mses_f = []\n",
    "    for g in loader:\n",
    "        mses_f.append(float(((model(g.x, g.edge_index) - g.y)**2).mean().item()))\n",
    "    mse_f = float(np.mean(mses_f))\n",
    "\n",
    "    out = []\n",
    "    for op in ops:\n",
    "        mses_s = []\n",
    "        for g in loader:\n",
    "            x = g.x.clone()\n",
    "            node = op[\"node\"]\n",
    "            new_val = op[\"value_fn\"](float(x[node,0].item())) if \"value_fn\" in op else float(op[\"value_const\"])\n",
    "            try:\n",
    "                yhat_s = model.do_intervention(\n",
    "                    x, g.edge_index,\n",
    "                    intervened_nodes=[node],\n",
    "                    new_feature_values=torch.tensor([new_val]).float()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                x[node,0] = new_val\n",
    "                yhat_s = model(x, g.edge_index)\n",
    "            mses_s.append(float(((yhat_s - g.y)**2).mean().item()))\n",
    "        mse_s = float(np.mean(mses_s))\n",
    "        out.append({\"stress_name\": op[\"name\"], \"mse_factual\": mse_f,\n",
    "                    \"mse_stress\": mse_s, \"degradation_ratio\": float(mse_s/(mse_f+1e-12))})\n",
    "    return out\n",
    "\n",
    "\n",
    "# build ops\n",
    "BAS_IDX, MOM_IDX = ds.node_map[\"BAS\"], ds.node_map[\"Mom\"]\n",
    "DELTA_BAS = 0.5\n",
    "\n",
    "ops = [\n",
    "    {\"name\": \"do_BAS_plus_delta\", \"node\": BAS_IDX, \"value_fn\": lambda v: v + DELTA_BAS},\n",
    "    {\"name\": \"do_MOM_plus_delta\", \"node\": MOM_IDX, \"value_fn\": lambda v: v + DELTA_BAS},\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"per_edge\": model_per_edge.eval().cpu(),\n",
    "    \"shared\":   model_shared.eval().cpu(),\n",
    "    \"gcn\":      baseline_model.eval().cpu(),\n",
    "}\n",
    "\n",
    "stress = {name: stress_degradation(m, val_loader, ops) for name, m in models.items()}\n",
    "print(stress)\n",
    "\n",
    "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
    "with open(os.path.join(OUTPUTS_DIR, \"stress_finance.json\"), \"w\") as f:\n",
    "    json.dump(stress, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = []\n",
    "for model_name, lst in stress.items():\n",
    "    for d in lst:\n",
    "        r = d.copy()\n",
    "        r[\"model\"] = model_name\n",
    "        rows.append(r)\n",
    "df = pd.DataFrame(rows)[[\"model\",\"stress_name\",\"mse_factual\",\"mse_stress\",\"degradation_ratio\"]]\n",
    "\n",
    "# --- Plot 1: degradation ratio under do(BAS = BAS + Δ) ---\n",
    "plt.figure(figsize=(6,4))\n",
    "subset = df[df[\"stress_name\"]==\"do_BAS_plus_delta\"]\n",
    "plt.bar(subset[\"model\"], subset[\"degradation_ratio\"])\n",
    "plt.title(\"Stress: do(BAS = BAS + Δ) — Degradation Ratio\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MSE_stress / MSE_factual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, \"stress_degradation_do_BAS.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 2: degradation ratio under do(Mom = Mom + Δ) ---\n",
    "plt.figure(figsize=(6,4))\n",
    "subset2 = df[df[\"stress_name\"]==\"do_MOM_plus_delta\"]\n",
    "plt.bar(subset2[\"model\"], subset2[\"degradation_ratio\"])\n",
    "plt.title(\"Stress: do(Mom = Mom + Δ) — Degradation Ratio\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MSE_stress / MSE_factual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, \"stress_degradation_do_MOM.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 3: factual MSE (mean across rows for each model) ---\n",
    "plt.figure(figsize=(6,4))\n",
    "mse_factual = df.groupby(\"model\")[\"mse_factual\"].mean().reset_index()\n",
    "plt.bar(mse_factual[\"model\"], mse_factual[\"mse_factual\"])\n",
    "plt.title(\"Factual MSE (Val split)\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MSE (factual)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, \"factual_mse.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
